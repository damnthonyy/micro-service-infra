import fs from "fs";
import OpenAI from "openai";
import dotenv from "dotenv";

dotenv.config();

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function generateLLMFeedback() {
  const reportPath = "spectral-report.json";
  if (!fs.existsSync(reportPath)) {
    console.error("‚ùå Aucun fichier spectral-report.json trouv√© !");
    process.exit(1);
  }

  const report = JSON.parse(fs.readFileSync(reportPath, "utf8"));
  const explanations = [];

  for (const issue of report) {
    const prompt = `
    Voici une erreur Spectral d√©tect√©e lors de la validation d'une spec OpenAPI.
    Explique le probl√®me en termes simples et propose une correction :
    - R√®gle : ${issue.code}
    - Message : ${issue.message}
    - Chemin : ${issue.path?.join(".")}
    `;

    try {
      const completion = await client.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: prompt }],
      });

      const explanation = completion.choices[0].message.content.trim();

      explanations.push({
        code: issue.code,
        message: issue.message,
        path: issue.path,
        explanation,
      });

      console.log(`üí° [${issue.code}] ${explanation}\n`);
    } catch (err) {
      console.error(`‚ö†Ô∏è Erreur lors de l'appel LLM : ${err.message}`);
    }
  }

  fs.writeFileSync("spectral-llm-report.json", JSON.stringify(explanations, null, 2));
  console.log("\n‚úÖ Rapport enrichi enregistr√© dans spectral-llm-report.json");
}

generateLLMFeedback();
